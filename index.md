---
layout: default
---

### About Me
* * *


I am a Faculty Fellow at the Center for Data Science at NYU.
I obtained my PhD in Computer Science from the Courant Institute, NYU, where I was fortunate to be advised by [Prof. Rajesh Ranganath](https://cims.nyu.edu/~rajeshr/).
During my PhD, I was partially supported by the [Apple Scholars in AI/ML PhD fellowship](https://machinelearning.apple.com/updates/apple-scholars-aiml-2022).


My research closes the gap between how models are built and how they will be used: out-of-distribution generalization, causality, interpretability, and more generally feature learning. I currently work on improving generalization in ML models where key techniques rely on understanding the role of gradients on feature learning. 

My earlier work focused on making models generalize across different populations ([Better representations for OOD](https://arxiv.org/abs/2107.00520), [Shortcut learning due to gradients](https://arxiv.org/abs/2308.12553)). The was informed by insights and techniques from work in causal inference in settings standard assumptions like ignorability and positivity/overlap do not hold. My primary application of interest is AI for healthcare (e.g. [classifying medical images](https://arxiv.org/abs/2107.00520) and [survival analysis](https://arxiv.org/abs/2101.05346)), but I also hold an interest in ML for science in general ([ML for particle discovery](https://iopscience.iop.org/article/10.1088/2632-2153/ad780c/meta)) .


I'm eternally excited about new ideas and finding good applications for my work! Shoot me an email if you want to chat!

### News 
* * * 
  1. **Oct 2024**: Two papers at NeurIPS 2024,  [Explanations that reveal all through the definition of Encoding](https://arxiv.org/abs/2411.02664) lead by Nhi and I, [Multi-modal contrastive learning with SYMILE](https://arxiv.org/abs/2411.01053) led by Adrial Saporta.

  2. **August  2024**: Defended my PhD! Dissertation link coming soon.
     
  4. **June 2024**: Nuisances via Negativa accepted by TMLR; [link](https://arxiv.org/abs/2210.01302).
     
  1. **Oct 2023**: Gave a talk about OOD generalization in health at INFORMS.

  2. **Sept 2023**: New paper accepted at NeurIPS 2023; [link](https://arxiv.org/abs/2308.12553).
 
  1. **July 2023**: The second SCIS workshop was a success at ICML 2023; [link](https://sites.google.com/view/scis-workshop-23)

  2. **April 2023**: DIET was published at AISTATS; [link](https://arxiv.org/abs/2208.08579).

  1. **July 2022**: Organized the SCIS workshop at ICML 2022; [website](https://sites.google.com/view/scis-workshop/home).

  1. **March 2022, Very happy to be a recipient of the Apple Scholars in AI/ML PhD Fellowship!** [announcement](https://machinelearning.apple.com/updates/apple-scholars-aiml-2022)  
  
  2. **March 2022, Updated version of NuRD on arxiv with code and improved results!** [link](https://arxiv.org/abs/2107.00520) 
  
  4. **January 2022, NuRD published at ICLR 2022 and work led by Mark Goldstein published at CLeaR 2022;** [link](https://arxiv.org/abs/2112.00881).   

  6. **Oct' 21, Named Rising Star by the Trustworthy ML initiative**
  
  7. **June' 21, New work on arxiv:** What sort of predictive models come with performance guarantees under spurious correlations induced by a relationship between the label and some nuisance variables that are correlated on the covariates? [Out-of-distribution Generalization in the Presence of Nuisance-Induced Spurious Correlations](https://arxiv.org/abs/2107.00520)   

  8. **Apr' 21, Link to work at AISTATS, 2021; Led by Mukund Sudarshan**: A new contrarian test statistic to use in CRTs to improve robustness to mis-specified covariate distributions. [CONTRA:Contrarian statistics for controlled variable selection](http://proceedings.mlr.press/v130/sudarshan21a.html)

  9. **Nov' 20. Links to my work at NeurIPS 2020 along with punchlines (shoot me an email if these interest you!)**:  
      - *General method for causal estimation from instrumental variables using only treatment process assumptions*: [General Control Functions for Causal Estimation from IVs](https://papers.nips.cc/paper/2020/hash/604f2c31e67034642b288d76a8df11d5-Abstract.html) 
      - *Fundamental nonparametric assumptions for causal estimation using functional confounders which violate positivity*:  [Causal Estimation with Functional Confounders
](https://papers.nips.cc/paper/2020/hash/36dcd524971019336af02550264b8a08-Abstract.html) 
      - *Add-on differentiable loss to improve calibration of survival models allowing explicit trade-off with predictive quality*: [X-CAL: Explicit Calibration for Survival Analysis
](https://papers.nips.cc/paper/2020/hash/d4a93297083a23cc099f7bd6a8621131-Abstract.html) 

<!-- 1. Sept'20. 3 papers at NeurIPS 2020 including [GCFN](https://arxiv.org/abs/1907.03451). New versions coming soon.
1. Sept'20. Helping out a bit with the [ML4H](https://ml4health.github.io/2020/) workshop. Submit all your recent amazing healthcare papers!
1. July'20. Qualified. Slides coming.
1. July'19. [Generalized Control Functions via Variational Decoupling ](https://arxiv.org/abs/1907.03451) up on arXiv.
2. Oct'18. [Removing Hidden Confounding by Experimental Grounding](https://papers.nips.cc/paper/8286-removing-hidden-confounding-by-experimental-grounding) in NeurIPS 2018. -->

### Olds

* * *

I was an intern in the summer of 2019 in Adobe Research, San Jose working on bayesian attribution models for ad targeting. Previously, I worked as a Software Developer at [DBMI, Columbia University](https://www.dbmi.columbia.edu/). In 2017, I completed my MS in CS, also at NYU. I was introduced to causal inference in the [Clinical Machine Learning group](clinicalml.org), where I worked with two amazing mentors, [Prof. Uri Shalit](https://web.iem.technion.ac.il/en/people/userprofile/urishalit.html) and [Prof. David Sontag](https://people.csail.mit.edu/dsontag/). My fateful but fun undergrad was from [IIT Madras](https://www.iitm.ac.in), where I was enrolled in the EE department.

<!-- ## Header 2

> This is a blockquote following a header.
>
> When something is important enough, you do it even if the odds are not in your favor.

### Header 3

```js
// Javascript code with syntax highlighting.
var fun = function lang(l) {
  dateformat.i18n = require('./lang/' + l)
  return true;
}
```

```ruby
# Ruby code with syntax highlighting
GitHubPages::Dependencies.gems.each do |gem, version|
  s.add_dependency(gem, "= #{version}")
end
``` -->

<!-- #### Header 4

*   This is an unordered list following a header.
*   This is an unordered list following a header.
*   This is an unordered list following a header.

##### Header 5

1.  This is an ordered list following a header.
2.  This is an ordered list following a header.
3.  This is an ordered list following a header. -->

<!-- ###### Header 6

| head1        | head two          | three |
|:-------------|:------------------|:------|
| ok           | good swedish fish | nice  |
| out of stock | good and plenty   | nice  |
| ok           | good `oreos`      | hmm   |
| ok           | good `zoute` drop | yumm  | -->

<!-- ### There's a horizontal rule below this.

* * *

### Here is an unordered list:

*   Item foo
*   Item bar
*   Item baz
*   Item zip -->

<!-- ### And an ordered list:

1.  Item one
1.  Item two
1.  Item three
1.  Item four -->

<!-- ### And a nested list:

- level 1 item
  - level 2 item
  - level 2 item
    - level 3 item
    - level 3 item
- level 1 item
  - level 2 item
  - level 2 item
  - level 2 item
- level 1 item
  - level 2 item
  - level 2 item
- level 1 item -->

<!-- ### Small image

![Octocat](https://github.githubassets.com/images/icons/emoji/octocat.png)

### Large image

![Branching](https://guides.github.com/activities/hello-world/branching.png) -->


<!-- ### Definition lists can be used with HTML syntax.

<dl>
<dt>Name</dt>
<dd>Godzilla</dd>
<dt>Born</dt>
<dd>1952</dd>
<dt>Birthplace</dt>
<dd>Japan</dd>
<dt>Color</dt>
<dd>Green</dd>
</dl>

```
Long, single-line code blocks should not wrap. They should horizontally scroll if they are too long. This line should be long enough to demonstrate this.
```

```
The final element.
``` -->
